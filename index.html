<!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<!doctype html>
<html lang="en-US">
<head>
  <meta charset="utf-8">
  <title>Blogasaurus Home</title>
  <!-- <link rel="stylesheet" href="/winlabsd2021/static/css/index.css"> -->
  <link rel="stylesheet" href="/Users/mayashankar/winlabsd2021/static/css/index.css">
</head>
<body>
  <div id="body">
    <script src="/winlabsd2021/static/js/script.js"></script>
    <div id="intro">
      <h1>Analyzing Social Distancing with Sensory Input</h1>
      <h3>Rutgers WINLAB</h3>
    </div>
    <div id="about">
      <h2>Objective</h2>
      <p>Blah blah blah some words</p>
    </div>
    <div id="pipeline">
      <div id="pipeline-intro">
        <h2>How It Works</h2>
        <p>Whole bunch of images with href tags</p>
      </div>
      <div id="pipeline-raw">
        <img src="https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png" alt="raw image">
        <p>Our image data is largely dashcam images taken in New York City.
          The images were captured in all five boroughs and at all times of day.
          Images provided by Nexar.</p>
        <p>Next Image</p>
      </div>
      <div id="pipeline-dim">
        <img src="https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png" alt="raw image">
        <p>We noticed that the object detection model was havinng trouble identifying people in dim images.
          To make the results more clear, we sorted our pictures by time. Any pictures taken at night were
          discarded as no people would be detected. </p>
        <p>Previous Image - Next Image</p>
      </div>
      <div id="pipeline-yolo">
        <img src="https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png" alt="raw image">
        <p>We ran the YOLOv3 object detection model on our images.
          We paired this with a script to draw colorful boxes around any human YOLO detected.
          We sorted out any images where YOLO detected no people, including images with only
        blurry or partial representations of people.</p>
        <p>Previous Image - Next Image</p>
      </div>
      <div id="pipeline-patch">
        <img src="https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png" alt="raw image">
        <p>One idea we tried was cropping the image around the detected people with a script.
          We ran these image patches through a program to increase the resolution of the patches.
          Between these four super-resolution methods, ESPCN worked the best,
          because we detected the most people with this method.</p>
      </div>
      <div id="pipeline-final">
        <img src="https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png" alt="raw image">
        <p>We do stuff</p>
        <p>Previous Imagee</p>
      </div>
    </div>
    <div id="results">
      <h2>Results</h2>
      <p>Some pictures of graphy things</p>
    </div>
    <div id="people">
      <h2>Who We Are</h2>
      <p>Advisors: Tahiya, Prof. Ortiz<br>
      Team (with pictures): Justin Taqiya, Maya, Aryan, Ansh, Sonia</p>
    </div>
  </body>
  </html>
